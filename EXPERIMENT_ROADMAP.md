# ì‹¤í—˜ ì„¤ê³„ ë° ì‹¤í–‰ ë¡œë“œë§µ

ì´ ë¬¸ì„œëŠ” HeaderRAG í”„ë¡œì íŠ¸ì˜ ì‹¤í—˜ ì„¤ê³„ ë° ì‹¤í–‰ ë‹¨ê³„ë³„ ê³„íšì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤.

## ğŸ“‹ ëª©ì°¨

1. [Phase 1: ì‹¤í—˜ ë©”íŠ¸ë¦­ í™•ì • ë° ê²€ì¦](#phase-1-ì‹¤í—˜-ë©”íŠ¸ë¦­-í™•ì •-ë°-ê²€ì¦)
2. [Phase 2: íŒŒì¼ëŸ¿ ì‹¤í—˜](#phase-2-íŒŒì¼ëŸ¿-ì‹¤í—˜)
3. [Phase 3: ì „ì²´ ê·œëª¨ ì‹¤í—˜](#phase-3-ì „ì²´-ê·œëª¨-ì‹¤í—˜)
4. [Phase 4: ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”](#phase-4-ê²°ê³¼-ë¶„ì„-ë°-ì‹œê°í™”)

---

## ğŸ¯ Phase 1: ì‹¤í—˜ ë©”íŠ¸ë¦­ í™•ì • ë° ê²€ì¦ (1-2ì£¼)

### 1.1 í‘œ íŒŒì‹± í‰ê°€ ë©”íŠ¸ë¦­ êµ¬í˜„ âœ…

#### í•µì‹¬ ë©”íŠ¸ë¦­

**TEDS (Tree Edit Distance-based Similarity)**
- í‘œ êµ¬ì¡° ì •í™•ë„ì˜ í•™ìˆ  í‘œì¤€ ë©”íŠ¸ë¦­
- HTML íŠ¸ë¦¬ êµ¬ì¡°ë¡œ ë³€í™˜ í›„ íŠ¸ë¦¬ í¸ì§‘ ê±°ë¦¬ ê³„ì‚°
- 0.90 ì´ìƒì´ë©´ ìš°ìˆ˜, 0.80 ì´í•˜ë©´ ë¬¸ì œ ìˆìŒ
- ë‹¨ì : í–‰ ëˆ„ë½ì´ ì—´ ëˆ„ë½ë³´ë‹¤ ë†’ì€ í˜ë„í‹° (íŠ¸ë¦¬ êµ¬ì¡° íŠ¹ì„±)

**GriTS (Grid Table Similarity)** â­ ê°€ì¥ ì¶”ì²œ
- í‘œë¥¼ 2D ë°°ì—´ë¡œ í•´ì„, í–‰/ì—´ ë™ë“± ì²˜ë¦¬
- ì„¸ ê°€ì§€ ì„¸ë¶€ ë©”íŠ¸ë¦­:
  - **GriTS-Content**: ì…€ í…ìŠ¤íŠ¸ í¸ì§‘ ê±°ë¦¬
  - **GriTS-Topology**: rowspan/colspan ì¼ì¹˜ë„
  - **GriTS-Location**: ì…€ ê³µê°„ ì¢Œí‘œ IoU
- 0.85-0.95ê°€ ìš°ìˆ˜ ì ìˆ˜

**í—¤ë” ê°ì§€ ì •í™•ë„**
- Precision, Recall, F1 for header cells
- ë³‘í•© ì…€ ì²˜ë¦¬ ì •í™•ë„

#### êµ¬í˜„ ìƒíƒœ

âœ… `src/evaluation/parsing_metrics.py`ì— êµ¬í˜„ ì™„ë£Œ
- `ParsingMetrics` í´ë˜ìŠ¤
- `calculate_teds()`: TEDS ê³„ì‚°
- `calculate_grits()`: GriTS ê³„ì‚° (Content, Topology, Location)
- `calculate_header_metrics()`: í—¤ë” ê°ì§€ ì •í™•ë„

#### ì‚¬ìš© ì˜ˆì‹œ

```python
from src.evaluation.parsing_metrics import ParsingMetrics

metrics = ParsingMetrics()

# GriTS ê³„ì‚°
grits_results = metrics.calculate_grits(predicted_table, ground_truth_table)
# {'grits_content': 0.92, 'grits_topology': 0.88, 'grits_location': 0.90, 'grits_overall': 0.90}

# í—¤ë” ë©”íŠ¸ë¦­
header_results = metrics.calculate_header_metrics(predicted_structure, ground_truth_structure)
# {'header_precision': 0.95, 'header_recall': 0.93, 'header_f1': 0.94, 'merged_cell_accuracy': 0.91}

# ì¢…í•© í‰ê°€
all_metrics = metrics.evaluate_parsing(predicted_table, ground_truth_table)
```

---

### 1.2 RAG í‰ê°€ ë©”íŠ¸ë¦­ êµ¬í˜„ âœ…

#### RAGAS í”„ë ˆì„ì›Œí¬ í•„ìˆ˜ ë©”íŠ¸ë¦­

**ê²€ìƒ‰(Retrieval) í‰ê°€:**
- **Context Precision**: ê´€ë ¨ ë¬¸ì„œê°€ ìƒìœ„ ìˆœìœ„ì— ìˆëŠ”ì§€ (0-1)
- **Context Recall**: Ground truth ëŒ€ë¹„ ê²€ìƒ‰ëœ ë¬¸ì„œ ë¹„ìœ¨
- **Context Relevance**: ê²€ìƒ‰ëœ ë¬¸ì„œì™€ ì§ˆë¬¸ì˜ ê´€ë ¨ì„±

**ìƒì„±(Generation) í‰ê°€:**
- **Faithfulness**: ë‹µë³€ì´ ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ì— ì¶©ì‹¤í•œì§€ (0-1)
  - ë‹µë³€ì„ ê°œë³„ ì£¼ì¥(claims)ìœ¼ë¡œ ë¶„í•´
  - ê° ì£¼ì¥ì´ ì»¨í…ìŠ¤íŠ¸ì—ì„œ ì§€ì›ë˜ëŠ”ì§€ ê²€ì¦
  - ê³µì‹: Faithfulness = |ì§€ì›ëœ ì£¼ì¥| / |ì „ì²´ ì£¼ì¥|
- **Answer Relevance**: ë‹µë³€ê³¼ ì§ˆë¬¸ì˜ ê´€ë ¨ì„±
  - ë‹µë³€ìœ¼ë¡œë¶€í„° ì—­ìœ¼ë¡œ ì§ˆë¬¸ ìƒì„±
  - ì›ë˜ ì§ˆë¬¸ê³¼ cosine similarity ê³„ì‚°
- **Answer Correctness**: Ground truth ëŒ€ë¹„ ì •ë‹µ ì •í™•ë„
  - Factual Correctness + Answer Similarity ê°€ì¤‘ í•©
- **Answer Hallucination**: ì»¨í…ìŠ¤íŠ¸ì— ì—†ëŠ” ì •ë³´ ìƒì„± ë¹„ìœ¨

**ê¶Œì¥ ì¡°í•©**: Faithfulness + Factual Correctnessê°€ ì „ë¬¸ê°€ í‰ê°€ì™€ ê°€ì¥ ì¼ì¹˜

#### êµ¬í˜„ ìƒíƒœ

âœ… `src/evaluation/ragas_metrics.py`ì— êµ¬í˜„ ì™„ë£Œ
- `RAGASMetrics` í´ë˜ìŠ¤
- ëª¨ë“  RAGAS ë©”íŠ¸ë¦­ êµ¬í˜„
- RAGAS ë¼ì´ë¸ŒëŸ¬ë¦¬ í†µí•© (ì„ íƒì )

#### ì‚¬ìš© ì˜ˆì‹œ

```python
from src.evaluation.ragas_metrics import RAGASMetrics

ragas_metrics = RAGASMetrics()

# ì¢…í•© RAG í‰ê°€
results = ragas_metrics.evaluate_rag(
    question="ë§¤ì¶œì•¡ì€ ì–¼ë§ˆì¸ê°€ìš”?",
    answer="2023ë…„ ë§¤ì¶œì•¡ì€ 100ì–µì›ì…ë‹ˆë‹¤.",
    contexts=["ë§¤ì¶œì•¡: 100ì–µì›", "ì—°ë„: 2023"],
    ground_truth_answer="100ì–µì›",
    ground_truth_contexts=["ë§¤ì¶œì•¡: 100ì–µì›"]
)
# {'faithfulness': 0.95, 'answer_relevancy': 0.92, 'context_precision': 1.0, ...}
```

---

### 1.3 í‘œ ë³µì¡ë„ ë©”íŠ¸ë¦­ ì •ì˜ âœ…

#### êµ¬ì¡°ì  ë³µì¡ë„ ì§€í‘œ

- **ë³‘í•© ì…€ ë¹„ìœ¨**: merged cells / total cells
- **í—¤ë” ê³„ì¸µ ê¹Šì´**: ì¤‘ì²©ëœ í—¤ë” ë ˆë²¨ ìˆ˜
- **Nested sub-table ìˆ˜**: í…Œì´ë¸” ë‚´ ë¶„ë¦¬ëœ ì˜ì—­ ìˆ˜
- **í–‰/ì—´ ë¹„ëŒ€ì¹­ì„±**: |rows - cols| / max(rows, cols)
- **ë¹ˆ ì…€ ë¹„ìœ¨**: empty cells / total cells

#### ì‹œê°ì  ë³µì¡ë„ ì§€í‘œ (WTW ë°ì´í„°ì…‹ ê¸°ë°˜)

- ê¸°ìš¸ê¸° ê°ë„
- í…ìŠ¤íŠ¸ ê²¹ì¹¨ ì •ë„
- í…Œë‘ë¦¬ ì™„ì „ì„±

#### ë³µì¡ë„ ë“±ê¸‰ ë¶„ë¥˜

- **Low**: ë³‘í•© ì…€ <10%, í—¤ë” 1ë ˆë²¨
- **Medium**: ë³‘í•© ì…€ 10-30%, í—¤ë” 2ë ˆë²¨
- **High**: ë³‘í•© ì…€ >30%, í—¤ë” 3+ ë ˆë²¨, nested sub-tables

#### êµ¬í˜„ ìƒíƒœ

âœ… `src/evaluation/complexity_metrics.py`ì— êµ¬í˜„ ì™„ë£Œ
- `ComplexityMetrics` í´ë˜ìŠ¤
- êµ¬ì¡°ì /ì‹œê°ì  ë³µì¡ë„ ê³„ì‚°
- ë³µì¡ë„ ë“±ê¸‰ ë¶„ë¥˜

#### ì‚¬ìš© ì˜ˆì‹œ

```python
from src.evaluation.complexity_metrics import ComplexityMetrics

complexity = ComplexityMetrics()

# ì¢…í•© ë³µì¡ë„ ê³„ì‚°
results = complexity.calculate_complexity(table_structure)
# {
#   'merged_cell_ratio': 0.15,
#   'header_depth': 2.0,
#   'structural_complexity_score': 0.45,
#   'complexity_level': 'medium',
#   ...
# }
```

---

## ğŸ§ª Phase 2: íŒŒì¼ëŸ¿ ì‹¤í—˜ (2-3ì£¼)

### 2.1 ì†Œê·œëª¨ ë°ì´í„°ì…‹ ì‹¤í—˜ âœ…

#### ë°ì´í„° ìƒ˜í”Œë§

- **PubTables-1M**: 100ê°œ (ë³µì¡ë„ë³„ ê· ë“± ìƒ˜í”Œë§)
- **TabRecSet**: 50ê°œ (ì˜ë¬¸/ì¤‘ë¬¸ ê° 25ê°œ)
- **KorWikiTabular**: 50ê°œ

#### ì‹¤í—˜ êµ¬ì„±

**ì‹¤í—˜ 1A: íŒŒì‹± ì„±ëŠ¥**
- ë ˆì´ë¸”ë§ ê¸°ë°˜ íŒŒì‹± (HeaderRAG)
- TATR ë² ì´ìŠ¤ë¼ì¸
- Sato ë² ì´ìŠ¤ë¼ì¸ (ì»¬ëŸ¼ íƒ€ì… ê²€ì¶œ)
- Naive íŒŒì‹± (pandas)
- í‰ê°€: GriTS, TEDS, í—¤ë” ì •í™•ë„

**ì‹¤í—˜ 2A: RAG ì„±ëŠ¥**
- KG ê¸°ë°˜ RAG (HeaderRAG)
- TableRAG ë² ì´ìŠ¤ë¼ì¸
- Tab2KG ë² ì´ìŠ¤ë¼ì¸
- Naive RAG (ë‹¨ìˆœ í…ìŠ¤íŠ¸)
- í‰ê°€: Faithfulness, Answer Relevancy, Context Precision

**ì‹¤í—˜ 3A: ë³µì¡ë„ ë¶„ì„ (íŒŒì¼ëŸ¿)**
- Low complexity: 20ê°œ
- Medium complexity: 20ê°œ
- High complexity: 20ê°œ
- ê° ë³µì¡ë„ë³„ ì‹¤í—˜ 1+2 ë°˜ë³µ

#### êµ¬í˜„ ìƒíƒœ

âœ… `experiments/pilot_experiments.py`ì— êµ¬í˜„ ì™„ë£Œ
- `PilotExperimentRunner` í´ë˜ìŠ¤
- ê³„ì¸µì  ìƒ˜í”Œë§ (`stratified_sampling`)
- ì‹¤í—˜ 1A, 2A, 3A êµ¬í˜„

#### ì‹¤í–‰ ë°©ë²•

```bash
# ì „ì²´ íŒŒì¼ëŸ¿ ì‹¤í—˜ ì‹¤í–‰
python experiments/run_pilot_experiments.py --experiment all --dataset pubtables1m --max_tables 100

# íŠ¹ì • ì‹¤í—˜ë§Œ ì‹¤í–‰
python experiments/run_pilot_experiments.py --experiment 1a --dataset korwiki_tabular
```

---

### 2.2 Ablation Study ì„¤ê³„ âœ…

#### ì‹¤í—˜ 1 Ablation

- **Baseline (Full)**: ë ˆì´ë¸”ë§ + í—¤ë” ê°ì§€ + ë³‘í•© ì…€ ì²˜ë¦¬
- **Ablation 1**: ë ˆì´ë¸”ë§ - í—¤ë” ê°ì§€
- **Ablation 2**: ë ˆì´ë¸”ë§ - ë³‘í•© ì…€ ì²˜ë¦¬
- **Ablation 3**: í—¤ë” ê°ì§€ë§Œ (ë ˆì´ë¸”ë§ ì œê±°)
- **Ablation 4**: Naive íŒŒì‹±

#### ì‹¤í—˜ 2 Ablation

- **Baseline (Full)**: KG ë³€í™˜ + êµ¬ì¡° ì •ë³´ + ì»¨í…ìŠ¤íŠ¸ ì„ë² ë”©
- **Ablation 1**: KG - êµ¬ì¡° ì •ë³´ (ë…¸ë“œë§Œ)
- **Ablation 2**: KG - ì»¨í…ìŠ¤íŠ¸ ì„ë² ë”©
- **Ablation 3**: ë‹¨ìˆœ ê·¸ë˜í”„ (ë ˆì´ë¸” ì—†ìŒ)
- **Ablation 4**: Naive RAG

#### í†µê³„ ë¶„ì„

- Paired t-testë¡œ ê° ì»´í¬ë„ŒíŠ¸ì˜ ìœ ì˜ì„± ê²€ì¦
- p-value < 0.05ë©´ í†µê³„ì  ìœ ì˜ë¯¸

#### êµ¬í˜„ ìƒíƒœ

âœ… `experiments/pilot_experiments.py`ì— êµ¬í˜„ ì™„ë£Œ
- `ablation_study_parsing()` ë©”ì„œë“œ
- í†µê³„ ë¶„ì„ í†µí•©

#### ì‹¤í–‰ ë°©ë²•

```bash
python experiments/run_pilot_experiments.py --experiment ablation --dataset pubtables1m
```

---

## ğŸ“Š Phase 3: ì „ì²´ ê·œëª¨ ì‹¤í—˜ (4-6ì£¼)

### 3.1 ë°ì´í„°ì…‹ í™•ì¥

#### ì‹¤í—˜ ê·œëª¨

- **PubTables-1M**: 1,000-5,000ê°œ (ë³µì¡ë„ ê³„ì¸µ ìƒ˜í”Œë§)
- **TabRecSet**: ì „ì²´ (38,177ê°œ) ë˜ëŠ” ëŒ€í‘œ ìƒ˜í”Œ 5,000ê°œ
- **KorWikiTabular**: 1,000-2,000ê°œ
- **FinTabNet**: 500ê°œ (ê¸ˆìœµ ë„ë©”ì¸ íŠ¹í™”)
- **WTW**: 500ê°œ (ê·¹ë‹¨ ì¼€ì´ìŠ¤)

#### ê³„ì¸µì  ìƒ˜í”Œë§ ì „ëµ

```python
# ë³µì¡ë„ë³„ ê· ë“± ìƒ˜í”Œë§
stratified_sample = (
    df.groupby('complexity_level')
    .sample(n=samples_per_level, random_state=42)
)
```

---

### 3.2 êµì°¨ ê²€ì¦ ë° í†µê³„ ë¶„ì„ âœ…

#### K-Fold Cross Validation (k=5)

- ë°ì´í„°ë¥¼ 5ê°œ foldë¡œ ë¶„í• 
- ê° foldì—ì„œ ëª¨ë“  ì‹¤í—˜ ë°˜ë³µ
- í‰ê·  ë° í‘œì¤€í¸ì°¨ ë³´ê³ 

#### í†µê³„ ê²€ì¦

- **Paired t-test**: HeaderRAG vs ê° ë² ì´ìŠ¤ë¼ì¸
- **Wilcoxon signed-rank test**: ë¹„ì •ê·œë¶„í¬ ì‹œ
- **Bonferroni correction**: ë‹¤ì¤‘ ë¹„êµ ë³´ì •

#### íš¨ê³¼ í¬ê¸° ê³„ì‚°

- **Cohen's d**: ì‹¤ì§ˆì  ì„±ëŠ¥ ì°¨ì´ ì¸¡ì •
- d > 0.8ì´ë©´ large effect

#### êµ¬í˜„ ìƒíƒœ

âœ… `experiments/statistical_analysis.py`ì— êµ¬í˜„ ì™„ë£Œ
- `StatisticalAnalyzer` í´ë˜ìŠ¤
- K-Fold Cross Validation
- Paired t-test, Wilcoxon test
- Cohen's d ê³„ì‚°
- Bonferroni correction

#### ì‚¬ìš© ì˜ˆì‹œ

```python
from experiments.statistical_analysis import StatisticalAnalyzer

analyzer = StatisticalAnalyzer()

# ë‘ ë°©ë²• ë¹„êµ
comparison = analyzer.compare_methods(
    method1_scores=[0.92, 0.93, 0.91, ...],
    method2_scores=[0.85, 0.86, 0.84, ...],
    method1_name="HeaderRAG",
    method2_name="Baseline"
)
# {'test': {'p_value': 0.001, 'is_significant': True}, 'effect_size': {'cohens_d': 1.2}, ...}
```

---

### 3.3 ë„ë©”ì¸ë³„ ë¶„ì„

#### ë°ì´í„°ì…‹ë³„ ì„±ëŠ¥ ë¹„êµ

| ë°ì´í„°ì…‹ | ë„ë©”ì¸ | ì–¸ì–´ | ë³µì¡ë„ |
|:--------|:------|:-----|:------|
| PubTables-1M | ê³¼í•™ | ì˜ë¬¸ | Medium |
| FinTabNet | ê¸ˆìœµ | ì˜ë¬¸ | High |
| TabRecSet | ì¼ë°˜ | ì˜/ì¤‘ | Mixed |
| KorWikiTabular | ë°±ê³¼ì‚¬ì „ | í•œê¸€ | Low-Medium |
| WTW | ì‹¤ì œí™˜ê²½ | ì˜/ì¤‘ | Extreme |

#### ë¶„ì„ ì§ˆë¬¸

- í•œêµ­ì–´ í‘œì—ì„œ HeaderRAGê°€ ë” íš¨ê³¼ì ì¸ê°€?
- ê¸ˆìœµ ë„ë©”ì¸ì²˜ëŸ¼ ë³µì¡í•œ í‘œì—ì„œ ì„±ëŠ¥ í–¥ìƒì´ ë” í°ê°€?
- ê·¹ë‹¨ ì¼€ì´ìŠ¤(WTW)ì—ì„œ ê°•ê±´ì„±ì´ ìœ ì§€ë˜ëŠ”ê°€?

---

## ğŸ“ˆ Phase 4: ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™” (2ì£¼)

### 4.1 ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸” âœ…

#### ì‹¤í—˜ 1 ê²°ê³¼ ì˜ˆì‹œ

| Method | GriTS â†‘ | TEDS â†‘ | Header F1 â†‘ | Cell Acc â†‘ |
|:-------|:--------|:-------|:------------|:-----------|
| Naive Parsing | 0.72 | 0.68 | 0.65 | 0.78 |
| TATR | 0.89 | 0.86 | 0.82 | 0.91 |
| Sato | 0.85 | 0.83 | 0.88 | 0.87 |
| **HeaderRAG (Ours)** | **0.93** | **0.91** | **0.94** | **0.95** |

#### ì‹¤í—˜ 2 ê²°ê³¼ ì˜ˆì‹œ

| Method | Faithfulness â†‘ | Answer Rel â†‘ | Context Prec â†‘ | F1 â†‘ |
|:-------|:---------------|:-------------|:---------------|:-----|
| Naive RAG | 0.68 | 0.72 | 0.65 | 0.71 |
| TableRAG | 0.79 | 0.81 | 0.78 | 0.82 |
| Tab2KG | 0.82 | 0.83 | 0.81 | 0.84 |
| **KG-RAG (Ours)** | **0.88** | **0.89** | **0.87** | **0.91** |

#### êµ¬í˜„ ìƒíƒœ

âœ… `experiments/result_analyzer.py`ì— êµ¬í˜„ ì™„ë£Œ
- `ResultAnalyzer` í´ë˜ìŠ¤
- `create_performance_table()`: ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸” ìƒì„±

---

### 4.2 ë³µì¡ë„ë³„ ì„±ëŠ¥ ë¶„ì„ âœ…

#### ì°¨íŠ¸ ìƒì„±

```python
# ë³µì¡ë„ë³„ ì„±ëŠ¥ ê³¡ì„ 
plt.plot(complexity_levels, your_method_scores, label='HeaderRAG')
plt.plot(complexity_levels, baseline_scores, label='Baseline')
plt.xlabel('Table Complexity')
plt.ylabel('GriTS Score')
plt.legend()
```

**ê¸°ëŒ€ ê²°ê³¼**: ë³µì¡ë„ê°€ ë†’ì„ìˆ˜ë¡ HeaderRAGì™€ ë² ì´ìŠ¤ë¼ì¸ ê°„ ê²©ì°¨ ì¦ê°€

#### êµ¬í˜„ ìƒíƒœ

âœ… `experiments/result_analyzer.py`ì— êµ¬í˜„ ì™„ë£Œ
- `plot_complexity_analysis()`: ë³µì¡ë„ë³„ ì„±ëŠ¥ ì°¨íŠ¸ ìƒì„±

---

### 4.3 ì˜¤ë¥˜ ë¶„ì„ (Error Analysis) âœ…

#### ì •ì„± ë¶„ì„

- HeaderRAGê°€ ì‹¤íŒ¨í•œ ì¼€ì´ìŠ¤ 100ê°œ ìƒ˜í”Œë§
- ì‹¤íŒ¨ ì›ì¸ ë¶„ë¥˜:
  - OCR ì˜¤ë¥˜
  - ê·¹ë‹¨ì  ë³‘í•© ì…€
  - Nested sub-table ë³µì¡ì„±
  - ë„ë©”ì¸ íŠ¹í™” ìš©ì–´

#### ê°œì„  ë°©í–¥ ë„ì¶œ

- ê° ì˜¤ë¥˜ ìœ í˜•ë³„ ë¹„ìœ¨ ê³„ì‚°
- í–¥í›„ ì—°êµ¬ì—ì„œ í•´ê²° ê°€ëŠ¥í•œ ë°©í–¥ ì œì‹œ

#### êµ¬í˜„ ìƒíƒœ

âœ… `experiments/result_analyzer.py`ì— êµ¬í˜„ ì™„ë£Œ
- `analyze_errors()`: ì˜¤ë¥˜ ë¶„ì„ ë° ì‹œê°í™”

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

ì¶”ê°€ ì„¤ì¹˜ í•„ìš”:
```bash
pip install zss ragas datasets scipy
```

### 2. íŒŒì¼ëŸ¿ ì‹¤í—˜ ì‹¤í–‰

```bash
# ì „ì²´ ì‹¤í—˜
python experiments/run_pilot_experiments.py --experiment all --dataset pubtables1m --max_tables 100

# íŒŒì‹± ì‹¤í—˜ë§Œ
python experiments/run_pilot_experiments.py --experiment 1a --dataset korwiki_tabular

# Ablation Study
python experiments/run_pilot_experiments.py --experiment ablation --dataset pubtables1m
```

### 3. ê²°ê³¼ ë¶„ì„

```python
from experiments.result_analyzer import ResultAnalyzer

analyzer = ResultAnalyzer()

# ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸” ìƒì„±
results = {...}  # ì‹¤í—˜ ê²°ê³¼ ë¡œë“œ
performance_table = analyzer.create_performance_table(
    results,
    metrics=['grits_overall', 'header_f1', 'teds'],
    output_path='results/performance_table.csv'
)

# ë³µì¡ë„ë³„ ë¶„ì„ ì°¨íŠ¸
analyzer.plot_complexity_analysis(
    complexity_results,
    metric='grits_overall',
    output_path='results/complexity_analysis.png'
)
```

---

## ğŸ“ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 1: ë©”íŠ¸ë¦­ êµ¬í˜„ âœ…
- [x] TEDS êµ¬í˜„
- [x] GriTS êµ¬í˜„
- [x] í—¤ë” ê°ì§€ ì •í™•ë„
- [x] RAGAS ë©”íŠ¸ë¦­ êµ¬í˜„
- [x] ë³µì¡ë„ ë©”íŠ¸ë¦­ ì •ì˜

### Phase 2: íŒŒì¼ëŸ¿ ì‹¤í—˜ âœ…
- [x] ì†Œê·œëª¨ ë°ì´í„°ì…‹ ì‹¤í—˜ í”„ë ˆì„ì›Œí¬
- [x] ê³„ì¸µì  ìƒ˜í”Œë§
- [x] Ablation Study ì„¤ê³„
- [x] í†µê³„ ë¶„ì„ í†µí•©

### Phase 3: ì „ì²´ ê·œëª¨ ì‹¤í—˜
- [ ] ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ í™•ì¥
- [x] êµì°¨ ê²€ì¦ ë„êµ¬
- [x] í†µê³„ ë¶„ì„ ë„êµ¬
- [ ] ë„ë©”ì¸ë³„ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸

### Phase 4: ê²°ê³¼ ë¶„ì„
- [x] ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸” ìƒì„±
- [x] ë³µì¡ë„ë³„ ë¶„ì„ ì°¨íŠ¸
- [x] ì˜¤ë¥˜ ë¶„ì„ ë„êµ¬
- [x] ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±

---

## ğŸ“š ì°¸ê³  ìë£Œ

- **TEDS**: [ë…¼ë¬¸ ë§í¬]
- **GriTS**: [ë…¼ë¬¸ ë§í¬]
- **RAGAS**: https://github.com/explodinggradients/ragas
- **Cohen's d**: íš¨ê³¼ í¬ê¸° í•´ì„ ê°€ì´ë“œ

---

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

1. **íŒŒì¼ëŸ¿ ì‹¤í—˜ ì‹¤í–‰**: ì†Œê·œëª¨ ë°ì´í„°ë¡œ íŒŒì´í”„ë¼ì¸ ê²€ì¦
2. **ë©”íŠ¸ë¦­ ê²€ì¦**: ê³„ì‚°ëœ ë©”íŠ¸ë¦­ì´ ì˜ˆìƒê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
3. **ë² ì´ìŠ¤ë¼ì¸ í†µí•©**: TATR, Sato, TableRAG ë“± ì‹¤ì œ í†µí•© í…ŒìŠ¤íŠ¸
4. **ëŒ€ê·œëª¨ ì‹¤í—˜ ì¤€ë¹„**: ë°ì´í„°ì…‹ í™•ì¥ ë° ì‹¤í–‰ ê³„íš ìˆ˜ë¦½



